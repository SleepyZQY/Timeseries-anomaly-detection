{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packages loaded\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import gc\n",
    "import calendar\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "print('packages loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Load saved cleaned df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls_filled:\n",
      "wtd_temp_mean          47434\n",
      "wtd_temp               46763\n",
      "kelv                   46763\n",
      "kelv2                  46763\n",
      "diff_from_av_T         46763\n",
      "diff_from_av_T2        46763\n",
      "f1d4_Values                4\n",
      "bd1_Values                 8\n",
      "f1d1_Values                2\n",
      "shift_1Df1d4_Values      100\n",
      "shift_1Df1d1_Values       98\n",
      "shift_1Dbd1_Values        96\n",
      "shift_7Df1d4_Values      676\n",
      "shift_7Df1d1_Values      674\n",
      "shift_7Dbd1_Values       672\n",
      "p1shft                    96\n",
      "peak1shft                 95\n",
      "t1shft                 46859\n",
      "p2shft                   192\n",
      "peak2shft                191\n",
      "t2shft                 46955\n",
      "p3shft                   288\n",
      "peak3shft                287\n",
      "t3shft                 47051\n",
      "p7shft                   672\n",
      "peak7shft                671\n",
      "t7shft                 47435\n",
      "p364shft               34944\n",
      "peak364shft            34943\n",
      "t364shft               81707\n",
      "p1shft_d               46763\n",
      "p7sfht_d               46763\n",
      "diff_from_av_T_sq      46763\n",
      "temp_streak_av         46763\n",
      "temp_streak            46770\n",
      "diff_rat               46763\n",
      "ahead_15                   1\n",
      "ahead_15_diff              2\n",
      "ahead_30                   2\n",
      "1hr_ahead                  4\n",
      "1hr_ahead_diff             6\n",
      "1hr_ahead_diff_diff        7\n",
      "1p5hr_ahead                6\n",
      "2hr_ahead                  8\n",
      "dtype: int64\n",
      "[0]\tvalidation_0-rmse:32.7125\n",
      "Will train until validation_0-rmse hasn't improved in 50 rounds.\n",
      "[1]\tvalidation_0-rmse:31.8201\n",
      "[2]\tvalidation_0-rmse:30.9569\n",
      "[3]\tvalidation_0-rmse:30.1355\n",
      "[4]\tvalidation_0-rmse:29.3448\n",
      "[5]\tvalidation_0-rmse:28.5612\n",
      "[6]\tvalidation_0-rmse:27.8047\n",
      "[7]\tvalidation_0-rmse:27.0838\n",
      "[8]\tvalidation_0-rmse:26.3757\n",
      "[9]\tvalidation_0-rmse:25.7664\n",
      "[10]\tvalidation_0-rmse:25.1032\n",
      "[11]\tvalidation_0-rmse:24.4642\n",
      "[12]\tvalidation_0-rmse:23.8791\n",
      "[13]\tvalidation_0-rmse:23.2799\n",
      "[14]\tvalidation_0-rmse:22.7008\n",
      "[15]\tvalidation_0-rmse:22.141\n",
      "[16]\tvalidation_0-rmse:21.6\n",
      "[17]\tvalidation_0-rmse:21.1481\n",
      "[18]\tvalidation_0-rmse:20.6466\n",
      "[19]\tvalidation_0-rmse:20.1627\n",
      "[20]\tvalidation_0-rmse:19.693\n",
      "[21]\tvalidation_0-rmse:19.2442\n",
      "[22]\tvalidation_0-rmse:18.8097\n",
      "[23]\tvalidation_0-rmse:18.3915\n",
      "[24]\tvalidation_0-rmse:17.9878\n",
      "[25]\tvalidation_0-rmse:17.6064\n",
      "[26]\tvalidation_0-rmse:17.2436\n",
      "[27]\tvalidation_0-rmse:16.8839\n",
      "[28]\tvalidation_0-rmse:16.5414\n",
      "[29]\tvalidation_0-rmse:16.2429\n",
      "[30]\tvalidation_0-rmse:15.9224\n",
      "[31]\tvalidation_0-rmse:15.6137\n",
      "[32]\tvalidation_0-rmse:15.3181\n",
      "[33]\tvalidation_0-rmse:15.0571\n",
      "[34]\tvalidation_0-rmse:14.7908\n",
      "[35]\tvalidation_0-rmse:14.5278\n",
      "[36]\tvalidation_0-rmse:14.2739\n",
      "[37]\tvalidation_0-rmse:14.051\n",
      "[38]\tvalidation_0-rmse:13.841\n",
      "[39]\tvalidation_0-rmse:13.6194\n",
      "[40]\tvalidation_0-rmse:13.406\n",
      "[41]\tvalidation_0-rmse:13.2008\n",
      "[42]\tvalidation_0-rmse:13.0081\n",
      "[43]\tvalidation_0-rmse:12.8203\n",
      "[44]\tvalidation_0-rmse:12.6425\n",
      "[45]\tvalidation_0-rmse:12.4719\n",
      "[46]\tvalidation_0-rmse:12.3071\n",
      "[47]\tvalidation_0-rmse:12.1511\n",
      "[48]\tvalidation_0-rmse:12.0028\n",
      "[49]\tvalidation_0-rmse:11.8811\n",
      "49\n",
      "MAPE:  0.06338268965100662\n",
      "MAE:  8.817329575022198\n",
      "Nulls_filled:\n",
      "wtd_temp_mean          47434\n",
      "wtd_temp               46763\n",
      "kelv                   46763\n",
      "kelv2                  46763\n",
      "diff_from_av_T         46763\n",
      "diff_from_av_T2        46763\n",
      "f1d4_Values                4\n",
      "bd1_Values                 8\n",
      "f1d1_Values                2\n",
      "shift_1Df1d4_Values      100\n",
      "shift_1Df1d1_Values       98\n",
      "shift_1Dbd1_Values        96\n",
      "shift_7Df1d4_Values      676\n",
      "shift_7Df1d1_Values      674\n",
      "shift_7Dbd1_Values       672\n",
      "p1shft                    96\n",
      "peak1shft                 95\n",
      "t1shft                 46859\n",
      "p2shft                   192\n",
      "peak2shft                191\n",
      "t2shft                 46955\n",
      "p3shft                   288\n",
      "peak3shft                287\n",
      "t3shft                 47051\n",
      "p7shft                   672\n",
      "peak7shft                671\n",
      "t7shft                 47435\n",
      "p364shft               34944\n",
      "peak364shft            34943\n",
      "t364shft               81707\n",
      "p1shft_d               46763\n",
      "p7sfht_d               46763\n",
      "diff_from_av_T_sq      46763\n",
      "temp_streak_av         46763\n",
      "temp_streak            46770\n",
      "diff_rat               46763\n",
      "ahead_15                   1\n",
      "ahead_15_diff              2\n",
      "ahead_30                   2\n",
      "1hr_ahead                  4\n",
      "1hr_ahead_diff             6\n",
      "1hr_ahead_diff_diff        7\n",
      "1p5hr_ahead                6\n",
      "2hr_ahead                  8\n",
      "dtype: int64\n",
      "MAPE:  0.04184265859361318\n",
      "MAE:  5.595296077846103\n"
     ]
    }
   ],
   "source": [
    "#evaluate the cell below before this one\n",
    "\n",
    "XY_val_fp = 'final_data/train_val.csv'\n",
    "XY_test_fp = 'final_data/train_test.csv'\n",
    "\n",
    "\n",
    "train_save_model(XY_val_fp, XY_test_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_feats(XY_fp):\n",
    "    \"\"\"load features and format time columns\"\"\"\n",
    "    XY = pd.read_csv('final_data/train_val.csv')\n",
    "    XY['Timestamp'] = pd.to_datetime(XY.Timestamp, format='%Y-%m-%d %H:%M:%S')\n",
    "    XY['date'] = XY['Timestamp'].dt.date\n",
    "    return XY\n",
    "\n",
    "def train_save_model(XY_val_fp, XY_test_fp, forecast='15min', model_type='xgboost', compute_cores=4):\n",
    "    \"\"\"Save trained model and validation results for specified model and forecast period.\n",
    "    \n",
    "    XY_val_fp - file path to the dataframe of the feats+target for validation\n",
    "    XY_test_fp - file path to the dataframe of the feats+target for final testing\n",
    "    forcast - Select one from ['15min', '1hour', '1day']. Specifies how far out the forecast is.\n",
    "    model_type - Select one from ['xgboost', 'lstm']. Which model to use.\"\"\"\n",
    "\n",
    "    \n",
    "    # define sets of columns that aren't valid features\n",
    "    not_1hour_ahead_feats = set(['ahead_15', 'ahead_15_diff' ,'ahead_30'])\n",
    "\n",
    "    not_day_ahead_feats = set(['ahead_15', 'ahead_15_diff' ,'ahead_30',\n",
    "                                 '1hr_ahead', '1hr_ahead_diff', '1p5hr_ahead', '2hr_ahead'])\n",
    "    \n",
    "    always_not_feats =  set(['arb_id','meter_id','obs_id', 'day','tdelt', 'DofW','diff_from_av','pred_values',\n",
    "                             'date','Timestamp','targ','863','938','relativemae','diff_rat','peak_hour',\n",
    "                             'dist_from_peak', 'peak_hour','data_set','f1d4_Values','bd1_Values',  'f1d1_Values',\n",
    "                         'obs_id','date','is_abnormal','Values','234_203','diff1','tdiff1'])\n",
    "\n",
    "    if forecast =='15min':\n",
    "        not_feats = always_not_feats\n",
    "    elif forecast =='1hour':\n",
    "        not_feats = always_not_feats.union(not_1hour_ahead_feats)\n",
    "    elif forecast =='1day':\n",
    "        not_feats = always_not_feats.union(not_day_ahead_feats)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    # x_colsd = joblib.load( 'day_ahead_feats.pkl') \n",
    "    if model_type == 'xgboost':\n",
    "        \n",
    "        #tune model parameters\n",
    "        #to be added\n",
    "        \n",
    "        #final validation results\n",
    "        save_tuned_model_results(XY_val_fp, forecast, model_type, compute_cores, not_feats, val_not_test=True)\n",
    "        \n",
    "        #final test\n",
    "        save_tuned_model_results(XY_test_fp, forecast, model_type, compute_cores, not_feats, val_not_test=False)\n",
    "        \n",
    "def get_features(df, not_feats):\n",
    "    \"\"\"Return list of features for model\"\"\"\n",
    "    x_feat_names = list(set(df) - not_feats)\n",
    "    y_feat_name ='diff_from_av'\n",
    "    \n",
    "    assert not y_feat_name in x_feat_names\n",
    "    \n",
    "    return x_feat_names, y_col\n",
    "\n",
    "        \n",
    "def save_tuned_model_results(XY_fp, forecast, model_type, compute_cores, not_feats,  val_not_test=True):\n",
    "    XY = pd.read_csv(XY_fp)\n",
    "    x_cols, y_col = get_features(XY, not_feats)\n",
    "    \n",
    "    original_null_values = XY.isnull().sum()\n",
    "    original_null_values=original_null_values[original_null_values>0]\n",
    "    XY.fillna(-300, inplace=True)\n",
    "    print('Nulls_filled:')\n",
    "    print(original_null_values)\n",
    "     \n",
    "    #get mask for train data\n",
    "    train_mask = (XY['data_set']==0)\n",
    "    not_train_mask = ~train_mask\n",
    "    \n",
    "    X_train, X_test = XY.loc[train_mask, x_cols].copy(), XY.loc[not_train_mask,x_cols].copy()\n",
    "    y_train, y_test = XY.loc[train_mask, y_col].copy(), XY.loc[not_train_mask, y_col].copy()\n",
    "\n",
    "    \n",
    "    tuned_parameter_filepath = 'modelparams_' + forecast + '_' + model_type + '.pkl'\n",
    "    model_params = joblib.load(tuned_parameter_filepath)\n",
    "    \n",
    "    reg = XGBRegressor(max_depth=model_params['max_depth'],\n",
    "                   learning_rate=model_params['learning_rate'],\n",
    "                   colsample_bylevel =model_params['colsample_bylevel'],\n",
    "                   min_child_weight=model_params['min_child_weight'],\n",
    "                   n_estimators=model_params['best_iteration'],\n",
    "                   colsample_bytree=model_params['colsample_bytree'],\n",
    "                   reg_alpha=model_params['reg_alpha'], \n",
    "                   reg_lambda=model_params['reg_lambda'],\n",
    "                   n_jobs=compute_cores)\n",
    "    \n",
    "    if val_not_test:\n",
    "        eval_set = [[X_test, y_test]]\n",
    "        reg.fit(X_train, y_train,\n",
    "               eval_set=eval_set,\n",
    "               early_stopping_rounds=50, verbose=True )\n",
    "        \n",
    "        \n",
    "        print(reg.best_iteration)\n",
    "        \n",
    "    else:\n",
    "        reg.fit(X_train, y_train)\n",
    "    \n",
    "    XY['pred_change'] = reg.predict(XY[x_cols])\n",
    "    XY['err'] =  XY[y_col] - XY['pred_change']\n",
    "\n",
    "    # the prediciton was the dif from av\n",
    "    XY['pred'] = XY['pred_change'] + XY['hour_av']\n",
    "    XY['err'] = XY['pred_change'] - XY['diff_from_av']\n",
    "    XY.index = XY.Timestamp\n",
    "\n",
    "    XY['AE'] = XY['err'].apply(abs)\n",
    "    XY['PE'] = XY['err'].divide(XY['Values'])\n",
    "    XY['APE'] = XY['PE'].apply(abs)\n",
    "\n",
    "    XY['1p2hourerr'] = XY['err'].rolling(2, center=True).sum()\n",
    "    XY['1hourerr'] = XY['err'].rolling(4, center=True).sum()\n",
    "    XY['4hourerr'] = XY['err'].rolling(4*4, center=True).sum()\n",
    "    XY['1week'] = XY['err'].rolling(7*4*24, center=True).sum()\n",
    "    XY['1day'] = XY['err'].rolling(1*4*24, center=True).sum()\n",
    "\n",
    "    print('MAPE: ', XY.loc[XY.data_set!=0,'APE'].mean())\n",
    "    print('MAE: ', XY.loc[XY.data_set!=0,'AE'].mean())\n",
    "    \n",
    "    #save results and model\n",
    "    if val_not_test:\n",
    "        val_test = 'val'\n",
    "    else:\n",
    "        val_test = 'test'\n",
    "    \n",
    "    augmented_df_filepath =  ('model_result' + forecast + '_' +\n",
    "                              model_type + '_' + val_test + '.csv')\n",
    "    XY.to_csv(augmented_df_filepath, index=False) \n",
    "        #storage is not a problem but should shave only new cols\n",
    "     \n",
    "    feature_list_file_path =  ('model_feat_list' + forecast + '_' + \n",
    "                               model_type + '_' + val_test + '.pkl')\n",
    "    joblib.dump(x_cols, feature_list_file_path)\n",
    "    \n",
    "    train_model_filepath =  ('model_trained' + forecast + '_' +\n",
    "                             model_type + '_' + val_test + '.pkl')\n",
    "    joblib.dump(reg, train_model_filepath) \n",
    "    \n",
    "    del XY\n",
    "    del X_train\n",
    "    del X_test\n",
    "    del y_train\n",
    "    del y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
